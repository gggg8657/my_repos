# '''
# detail:
# This is followed by training the detail model (i.e. 𝐸𝑑
# and 𝐹𝑑
# ) on VGGFace2 and VoxCeleb2 with a batch size of 6, with
# 3 images per subject, and parameters 𝜆𝑝ℎ𝑜𝐷 = 2.0, 𝜆𝑚𝑟 𝑓 = 5𝑒 − 2,
# 𝜆𝑠𝑦𝑚 = 5𝑒 − 3, 𝜆𝑑𝑐 = 1.0, and 𝜆𝑟𝑒𝑔𝐷 = 5𝑒 − 3.
# in config

# why:
# '''
# pretrained_modelpath: '/ps/scratch/yfeng/Data/Projects-data/DECA-training/training/DECA_SIGGRAPH/pretrain/model.tar'
output_dir: "/mnt/hdd/DJ_Training/train_only_au_loss"
pretrained_modelpath: "/home/cine/DJ/DECA/data/deca_model.tar"
dataset:
  batch_size: 8
  K: 1
train:
  train_detail: True
  resume: True
  max_epochs: 10
  max_steps: 1000000
  log_steps: 10
  vis_steps: 500
  checkpoint_steps: 1000 #1000 model.tar saved
  val_steps: 500
  eval_steps: 1000
dataset:
  training_data: ['vggface2', 'vox2']
# python main_train_deca_release.py --cfg configs/release_version/deca_coarse.yml